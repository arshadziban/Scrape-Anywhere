{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b945480",
   "metadata": {},
   "source": [
    "# Web Scraping Basics\n",
    "\n",
    "Web scraping is a way to **automatically collect information from websites**.  \n",
    "Think of it as using a program to read a web page, just like your browser does, but instead of looking at it, the program grabs the data you want.\n",
    "\n",
    "---\n",
    "\n",
    "## Let’s break down your points:\n",
    "\n",
    "### a) Use `requests` to fetch pages\n",
    "\n",
    "#### What is `requests`?\n",
    "\n",
    "- `requests` is a **Python library** (tool) that helps your code download web pages from the internet.\n",
    "- Imagine typing a website address in your browser and hitting enter.  \n",
    "  `requests` lets your code do the **same thing**—it can visit websites and get the page data for you!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d51d77",
   "metadata": {},
   "source": [
    "# Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "db8ecfff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "f2bd8ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://techsabyte.com/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "987a2337",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://techsabyte.com/'"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "5b0d9577",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "4a67ab84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<!doctype html>\\n<html lang=\"en\">\\n  <head>\\n    <meta charset=\"UTF-8\" />\\n    <!-- <link rel=\"icon\" type=\"image/svg+xml\" href=\"/vite.svg\" /> -->\\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\" />\\n    <title>TechsaByte</title>\\n    <script type=\"module\" crossorigin src=\"/assets/index-C1pstMX7.js\"></script>\\n    <link rel=\"stylesheet\" crossorigin href=\"/assets/index-Dq-yZx2N.css\">\\n  </head>\\n  <body>\\n    <div id=\"root\"></div>\\n  </body>\\n</html>\\n'"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18239cd6",
   "metadata": {},
   "source": [
    "### b) Parse HTML with BeautifulSoup\n",
    "\n",
    "#### What is “HTML”?\n",
    "\n",
    "- **HTML** is the code websites use to tell browsers what to display (text, images, buttons, etc.).\n",
    "\n",
    "#### What is “BeautifulSoup”?\n",
    "\n",
    "- **BeautifulSoup** is another **Python tool** that helps you read and understand (parse) the messy HTML code from a web page, so you can easily find the data you need."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc9bc61",
   "metadata": {},
   "source": [
    "# Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "769fe2e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "29cd251d",
   "metadata": {},
   "outputs": [],
   "source": [
    "html_code = \"<html><body><h1>Hello!</h1></body></html>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "c2ab065d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<html><body><h1>Hello!</h1></body></html>'"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "html_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "9dfe1b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(html_code, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "c3f79de5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello!'"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.h1.text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "963f4b32",
   "metadata": {},
   "source": [
    "### c) Extract text, links, tables, images\n",
    "\n",
    "With **BeautifulSoup**, you can pick out specific parts of a web page:\n",
    "\n",
    "- **Text:** The actual words on the page\n",
    "- **Links:** Website addresses (URLs) inside `<a>` tags\n",
    "- **Tables:** Data organized in rows and columns\n",
    "- **Images:** Picture links inside `<img>` tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "461da780",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello!'"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get all text from the HTML\n",
    "soup.get_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "98da8e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract all links\n",
    "for link in soup.find_all(\"a\"):\n",
    "    print(link.get(\"href\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "4147a23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract all images\n",
    "for img in soup.find_all(\"img\"):\n",
    "    print(img.get(\"src\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a496b4b",
   "metadata": {},
   "source": [
    "## In summary:\n",
    "\n",
    "- **`requests`** downloads web pages for you.\n",
    "- **BeautifulSoup** helps you read and pull out the parts you want.\n",
    "- You can then extract **text, links, tables, images**—whatever you need!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d592056e",
   "metadata": {},
   "source": [
    "# Real Life Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "9f895193",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "d36fd4f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://example.com/\"\n",
    "response = requests.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "652f6079",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(response.text, \"html.parser\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d1ea1a4",
   "metadata": {},
   "source": [
    "`\"html.parser\"`  \n",
    "This tells BeautifulSoup which parser to use to read the HTML.  \n",
    "`\"html.parser\"` is Python’s built-in HTML parser—it's fast and works well for most cases.  \n",
    "(There are other options, like `\"lxml\"` or `\"html5lib\"`, but `\"html.parser\"` is a good choice for beginners.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "a41fff61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Example Domain\\nExample Domain\\nThis domain is for use in illustrative examples in documents. You may use this\\n    domain in literature without prior coordination or asking for permission.\\nMore information...'"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Extract all text\n",
    "all_text = soup.get_text(separator=\"\\n\", strip=True)\n",
    "all_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "65efb81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to files\n",
    "with open(\"texts.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(all_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "33253079",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.iana.org/domains/example\n"
     ]
    }
   ],
   "source": [
    "# Extract all links\n",
    "for a_tag in soup.find_all(\"a\", href=True):\n",
    "    print(a_tag['href'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "447c2976",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"links.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for a_tag in soup.find_all(\"a\", href=True):\n",
    "        f.write(a_tag['href'] + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "af8cca6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract all image URLs\n",
    "for img_tag in soup.find_all(\"img\", src=True):\n",
    "    print(img_tag['src'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "6e453afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"images.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for img_tag in soup.find_all(\"img\", src=True):\n",
    "        f.write(img_tag['src'] + \"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
