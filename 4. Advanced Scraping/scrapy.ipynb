{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06e28c28",
   "metadata": {},
   "source": [
    "## What is Scrapy?\n",
    "\n",
    "**Scrapy** is a popular Python framework for web scraping and crawling.\n",
    "It lets you write small programs (called **spiders**) that automatically browse websites and collect data from many pages very quickly.\n",
    "\n",
    "**Why use Scrapy?**\n",
    "\n",
    "* It’s **fast** and **efficient** for big projects.\n",
    "* Handles things like requests, data extraction, and exporting data out of the box.\n",
    "* Easy to add advanced features (like pipelines and middlewares) as your project grows.\n",
    "\n",
    "**Real-life Example:**\n",
    "Imagine you want to collect the names and prices of all books from an online bookstore.\n",
    "With Scrapy, you can:\n",
    "\n",
    "* Tell it which website to visit.\n",
    "* Show it where to find the name and price on each page.\n",
    "* Scrapy will visit every book page, collect the data, and save it to a file for you—**automatically**.\n",
    "\n",
    "---\n",
    "\n",
    "## **Full Flow with Scrapy**\n",
    "\n",
    "Here’s how it all connects:\n",
    "\n",
    "1. **Scrapy Spider**: You write a spider that tells Scrapy what website to visit and what data to collect.\n",
    "2. **Pipelines**: Scrapy passes the collected data through pipelines to clean or save it.\n",
    "3. **Middlewares**: Scrapy uses middlewares to add extra rules (like delays, proxies, user-agent changes) while browsing.\n",
    "4. **Data Export**: Scrapy saves all your final, clean data into files (CSV, JSON, etc.), ready for you to use.\n",
    "\n",
    "---\n",
    "\n",
    "## Visual Diagram (Text Form)\n",
    "\n",
    "```\n",
    "[Website]\n",
    "    ↓\n",
    "[Scrapy Spider] → [Middlewares] → [Pipelines] → [Export File (CSV/JSON)]\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "**In Short:**\n",
    "\n",
    "* **Scrapy** is the engine.\n",
    "* **Spider** does the crawling.\n",
    "* **Middlewares** are helpers on the way.\n",
    "* **Pipelines** clean and save the results.\n",
    "* **Data export** gives you the final output.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abaad786",
   "metadata": {},
   "source": [
    "## Goal:\n",
    "I want to collect the title and price of all books from an online bookstore, and save them to a CSV file.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e76223f8",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
